{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d9ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from  nltk.tokenize import  word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02cc7ce",
   "metadata": {},
   "source": [
    "### 1.Use spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7eaecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spamUtf8.csv')\n",
    "# get data set number\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90609397",
   "metadata": {},
   "source": [
    "### pre-process  \n",
    "import nltk package;  \n",
    "Use regular expressions to do text clean;  \n",
    "Tokenize the cleaned sentence into words;  \n",
    "Remove stopwords from the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c999b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # remove EXPECT A-Za-z white space\n",
    "    newsentence = re.sub(re.compile(r'[^A-Za-z\\s+]'),'',sentence.strip().lower())\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    # replace mult_white space to one white space\n",
    "    newsentence = re.sub(pattern, ' ', newsentence)\n",
    "    word_tokens = word_tokenize(newsentence)\n",
    "    filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669a4b6",
   "metadata": {},
   "source": [
    "Delete unused columns;  \n",
    "Rename key column to \"label\" and \"text\"\n",
    "Perform preprocessing on the content of the text column and assign the result to the text column in the form of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5a150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  go jurong point crazy available bugis n great ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...\n",
       "3   ham                u dun say early hor u c already say\n",
       "4   ham        nah dont think goes usf lives around though"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conlumn = df.columns\n",
    "df.drop(conlumn[2:],axis=1,inplace=True)\n",
    "new_column = ['label','text']\n",
    "df.columns = new_column\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row.loc['text']\n",
    "    filtered_sentence = pre_process(sentence)\n",
    "    row.loc['text'] = ' '.join(filtered_sentence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3e34a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazy available bugis n great world la e buffet cine got amore wat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1519938",
   "metadata": {},
   "source": [
    "### 2.Use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "053370b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Uses the fit_transform to convert the text data into the TF-IDF feature matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "# Use \"get_feature_names_out\" method to retrieve the feature names from the TF-IDF vectorizer\n",
    "tfidf_features = tfidf_vectorizer.get_feature_names_out()\n",
    "# Calculates the number of features in the TF-IDF matrix \n",
    "len(tfidf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cce2e",
   "metadata": {},
   "source": [
    "### 3.Use feature selection with variance threshold  \n",
    "(use threshold level = 0.001) When the threshold is 0.01, no feature in the matrix has a variance greater than or equal to the specified threshold. So I define the threshold level = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea419bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "# Create instance of VarianceThreshold class and specify the threshold value\n",
    "variance_threshold = VarianceThreshold(threshold=threshold)\n",
    "# removes features with variance below the specified threshold\n",
    "tfidf_matrix_variance = variance_threshold.fit_transform(tfidf_matrix)\n",
    "# Use 'get_support()' to indicate which features were selected based on the variance threshold.\n",
    "selected_features = variance_threshold.get_support()\n",
    "# Calculate the number of features that passed the variance threshold\n",
    "# selected_features is a boolean mask, so sum() can get the number of the \"True\" from the selected_features\n",
    "selected_features.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4259cf",
   "metadata": {},
   "source": [
    "### 4.Removed features:  \n",
    "tfidf_features - elected_features = Removed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7802db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8247"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_features) - selected_features.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40bb20",
   "metadata": {},
   "source": [
    "### 5.Apply stratified hold-out  \n",
    "(use 70:30 ratio,shuffle = False,random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ab0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ratio of training set to test set is 7:3\n",
    "# data won't be shuffled\n",
    "x_train,x_test,y_train,y_test = train_test_split(tfidf_matrix_variance,df['label'].values,test_size = 0.3,shuffle = False,random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b44c2",
   "metadata": {},
   "source": [
    "### 6.1 train matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65d72a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 141)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train matrix shape\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bce9b6",
   "metadata": {},
   "source": [
    "### 6.2 test matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb1efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672, 141)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test matrix shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dec3ec",
   "metadata": {},
   "source": [
    "### 7.1 top 10 rows of train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a152210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top10 rows\n",
    "x_train[:10].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5c2ae",
   "metadata": {},
   "source": [
    "### 7.2 buttom 10 rows of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2b8c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get buttom10 rows\n",
    "x_train[-10:].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac80e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "csv_data = pd.read_csv('../assets/spam.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# delete Unnamed column\n",
    "csv_data = csv_data.loc[:, ~csv_data.columns.str.contains('^Unnamed')]\n",
    "csv_data.columns = ['label', 'text']\n",
    "# clear space\n",
    "def clearSpace(text):\n",
    "  pattern = re.compile(r'\\s+')\n",
    "  sentence = re.sub(pattern, ' ', text.lower())\n",
    "  return sentence.strip()\n",
    "\n",
    "# remove anything that is not English\n",
    "def removeEnglish(text):\n",
    "  pattern = re.compile(r'^[a-zA-Z]+$')\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_list = [w for w in word_tokens if not w in stop_words]\n",
    "  filtered_list = [w for w in filtered_list if pattern.match(w)]\n",
    "  return ' '.join(filtered_list)\n",
    "\n",
    "def clearSentence(text):\n",
    "  space_text = clearSpace(text)\n",
    "  filtered_list = removeEnglish(space_text)\n",
    "  return filtered_list\n",
    "\n",
    "# Preprocess text\n",
    "docs = csv_data['text'].apply(clearSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----feature_list counts: 7105\n"
     ]
    }
   ],
   "source": [
    "# init TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# use the fit_transform transform the docs\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# get feature\n",
    "feature_list = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# print('----TF-IDF\\n', X_tfidf)\n",
    "print('----feature_list counts:', len(feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply feature selection with variance threshold\n",
    "(threshold == 0.1, it will throw error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection and set threshold = 0.001\n",
    "threshold = 0.001\n",
    "selector = VarianceThreshold(threshold)\n",
    "X_selected = selector.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.how many feature you have removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features removed counts: 6950\n"
     ]
    }
   ],
   "source": [
    "# selected_features = selector.get_support()\n",
    "features_removed = X_tfidf.shape[1] - X_selected.shape[1]\n",
    "# print('features removed counts: ', len(feature_list) - selected_features.sum())\n",
    "print(f\"features removed counts: {features_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Apply stratified hold-out with 70:30 ratio, with no shuffle, random state = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified hold-out\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, \n",
    "    docs, \n",
    "    test_size=0.3, \n",
    "    random_state=1234, \n",
    "    # stratify=docs,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Report the shape of matrix for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (3900, 155)\n",
      "test_shape: (1672, 155)\n"
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "train_shape = X_train.shape\n",
    "test_shape = X_test.shape\n",
    "print('train_shape:', train_shape)\n",
    "print('test_shape:', test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Report the top 10 and buttom 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_10_rows\n",
      "   (0, 142)\t0.1934414974362614\n",
      "  (0, 40)\t0.16081723256683003\n",
      "  (0, 41)\t0.19160426362908617\n",
      "  (0, 36)\t0.1574042918397475\n",
      "  (1, 89)\t0.278979726023622\n",
      "  (2, 134)\t0.1399333473376727\n",
      "  (2, 125)\t0.13770940734010412\n",
      "  (2, 32)\t0.1291773438749615\n",
      "  (3, 1)\t0.3090166793888741\n",
      "  (3, 109)\t0.6207429378111018\n",
      "  (3, 28)\t0.34208730492608386\n",
      "  (4, 4)\t0.31997466807742914\n",
      "  (4, 128)\t0.27357082071110356\n",
      "  (5, 111)\t0.1738082424362937\n",
      "  (5, 119)\t0.18174488701480665\n",
      "  (5, 61)\t0.16596785147278276\n",
      "  (5, 7)\t0.18305898101099072\n",
      "  (5, 145)\t0.1962599074872638\n",
      "  (5, 48)\t0.1962599074872638\n",
      "  (5, 89)\t0.16312366637893552\n",
      "  (6, 61)\t0.4259234768966834\n",
      "  (8, 11)\t0.13766930526014834\n",
      "  (8, 15)\t0.40658158269686484\n",
      "  (8, 99)\t0.2135368880049105\n",
      "  (9, 74)\t0.36602529673707374\n",
      "  (9, 11)\t0.12747528710093337\n",
      "  (9, 32)\t0.3205037418850104\n"
     ]
    }
   ],
   "source": [
    "# top_10rows\n",
    "top_10_rows = X_train[:10]\n",
    "print('top_10_rows\\n', top_10_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom_10_rows\n",
      "   (0, 101)\t0.3816270673437317\n",
      "  (0, 129)\t0.26890856746636066\n",
      "  (1, 19)\t0.30157613531188215\n",
      "  (1, 11)\t0.18690860628718514\n",
      "  (1, 15)\t0.27600051013661603\n",
      "  (1, 99)\t0.28991126273558676\n",
      "  (1, 119)\t0.2570336358191113\n",
      "  (2, 145)\t0.5749958598344096\n",
      "  (3, 24)\t0.21084247864828234\n",
      "  (3, 14)\t0.22696698004105995\n",
      "  (3, 11)\t0.14251713495294333\n",
      "  (4, 151)\t0.4676683902144561\n",
      "  (5, 135)\t0.18418278910419777\n",
      "  (5, 74)\t0.22681908078461524\n",
      "  (5, 11)\t0.15798813743607587\n",
      "  (5, 15)\t0.23329480324138707\n",
      "  (5, 99)\t0.24505313763326958\n",
      "  (7, 55)\t0.4881963796330494\n",
      "  (7, 129)\t0.35918460409570163\n",
      "  (8, 109)\t0.29589942088809196\n",
      "  (8, 89)\t0.23704995804744491\n",
      "  (9, 90)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# bottom_10rows\n",
    "bottom_10_rows = X_train[-10:]\n",
    "print('bottom_10_rows\\n', bottom_10_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
